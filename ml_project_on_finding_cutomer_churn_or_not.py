# -*- coding: utf-8 -*-
"""ML project on finding cutomer  churn or not.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11I6AiBt0Lz0B7dUkP7Fm0VymN4YAKQdI

In this data, we have set of variables with churn column .  we have to find those customers who are going to churn.

**Importing libraries:**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

"""**importing dataset:**"""

df = pd.read_csv("/content/Churn_MV.csv")

"""**data analysis, visualization and preprocessing:**"""

df.head()

df.tail()

df.shape

df.info()

"""as we observe, there are some rows having ony 'NaN' for every feature

first let's remove those kind of rows:
"""

df.dropna(axis=0,how='all',inplace=True)

df.shape

"""as we observere number of rows droped from 6666 to 3333 , which means half of the rows in the dataset are useless"""

df.info()

df.describe()

"""**checking for null/missing  values:**"""

df.isnull().sum()

sns.heatmap(df.isnull(),cmap='viridis')

"""we have 50 missing values in 'Daily charges MV'"""

sns.boxplot(df['Daily Charges MV'])

"""as we observe there are outliers in 'Daily Charges MV' , we can't rely on mean value.  we use median to replace the missing values . """

median_val = df['Daily Charges MV'].median()
df['Daily Charges MV']= df['Daily Charges MV'].fillna(median_val)

sns.heatmap(df.isnull(),cmap='viridis')

"""as we filled the missing values , checking missing value imputation accuracy"""

sns.jointplot(x='Day Charge',y = 'Daily Charges MV',data=df,kind='reg')

"""it seems better, looking like good correlation

In our dataset , churn , Intl plan , VMail plan are filled with only 0 and 1 and the datatype is float64. 

so changing the datatypes into category
"""

df['Churn'] = df['Churn'].astype('category')
df['Intl Plan'] = df['Intl Plan'].astype('category')
df['VMail Plan'] = df['VMail Plan'].astype('category')

"""**dropping unwanted column:**"""

df.corr()

sns.heatmap(df.corr())

df.groupby('Churn').mean()

"""in this both 'Day charge ' and 'Daily charge MV ' are like mirror columns . 

we remove 'Daily charge MV ' cause we filled some values with median  so better to use ' Day charge' 
"""

df.drop(['Daily Charges MV'],axis=1,inplace=True)

#removing unwanted column
df.drop(['Area Code','Phone','State'],axis=1,inplace=True)

"""and also

Night Mins , Night Charge 0.999999

Eve Charge , Eve Mins 1.000000

Day Charge , Day Mins 1.000000

Intl Charge , Intl Mins 0.999993

are multicollinear variables so we only use one of them 
"""

df.drop(['Night Mins','Intl Mins','Eve Mins','Day Mins'],axis=1,inplace=True)

df.head()

"""**Data visualization:**"""

sns.countplot(x='Churn',data=df)

df.Churn.value_counts()

"""based on the plot , 'Churn' class is imbalanced

only 14.5% belongs to churned class
"""

sns.countplot(x='CustServ Calls',hue = 'Churn',data=df )

"""from the above plot , we may consider that customers are more likely to churn when customer calls increases"""

plt.figure(figsize=(10,6))
df[df['Churn']==1]['Day Charge'].hist(bins=35,color = 'blue',label = 'Churn 1',alpha = 0.6)
df[df['Churn']==0]['Day Charge'].hist(bins = 35,color = 'red',label = 'Churn 0',alpha = 0.6)
plt.legend()
plt.xlabel('DAY CHARGE')

"""from the above plot , we may consider that customers with high daily charge more likely to churn"""

plt.figure(figsize=(11,7))
sns.countplot(x ='Intl Plan',hue='Churn',data = df,palette='Set1')

"""the customers with initial plan are more likely to churn than """

sns.boxplot(x="Churn",y="Day Charge",data=df)

"""people are more likely to churn when 'Day charge' is higher"""

sns.countplot(x ='VMail Plan',hue='Churn',data = df,palette='Set1')

sns.boxplot(x="Churn",y="Eve Charge",data=df)

sns.boxplot(x="Churn",y="Night Charge",data=df)

"""so most of the people who are churned are the one who were gwtting the heavy bill

**managing Outliers:**
"""

sns.boxplot(df['Account Length'])

"""we have outliers in it,we will clip the otliers"""

df['Account Length'].clip(upper = 200,inplace = True)

#after clipping 
sns.boxplot(df['Account Length'])

sns.boxplot(df['VMail Message'])

sns.boxplot(df['Day Charge'])

print(df['Day Charge'].quantile(0.99))
print(df['Day Charge'].quantile(0.01))

df['Day Charge'].clip(lower=8.813,upper=51.88,inplace= True)

sns.boxplot(df['Eve Charge'])

print(df['Eve Charge'].quantile(0.99))
print(df['Eve Charge'].quantile(0.01))

df['Eve Charge'].clip(lower=6.76,upper=27.11,inplace= True)

sns.boxplot(df['Night Charge'])

print(df['Night Charge'].quantile(0.99))
print(df['Night Charge'].quantile(0.01))

df['Night Charge'].clip(lower=6.76,upper=27.11,inplace= True)

sns.boxplot(df['Intl Charge'])

print(df['Intl Charge'].quantile(0.99))
print(df['Intl Charge'].quantile(0.01))

df['Intl Charge'].clip(lower=0.9,upper=4.5,inplace= True)

sns.boxplot(df['Day Calls'])

print(df['Day Calls'].quantile(0.99))
print(df['Day Calls'].quantile(0.01))

df['Day Calls'].clip(lower=54,upper=146,inplace= True)

sns.boxplot(df['Eve Calls'])

print(df['Eve Calls'].quantile(0.99))
print(df['Eve Calls'].quantile(0.01))

df['Eve Calls'].clip(lower=53,upper=147,inplace= True)

sns.boxplot(df['Night Calls'])

print(df['Night Calls'].quantile(0.99))
print(df['Night Calls'].quantile(0.01))

df['Night Calls'].clip(lower=57,upper=146.7,inplace= True)

sns.boxplot(df['Intl Calls'])

print(df['Intl Calls'].quantile(0.99))
print(df['Intl Calls'].quantile(0.01))

df['Intl Calls'].clip(lower=1,upper=13,inplace= True)

"""**Separating x and y:**"""

X = df.drop('Churn',axis=1)
y = df['Churn']

X.head()

"""**encoding:**"""

X = pd.get_dummies(X,columns=['Intl Plan','VMail Plan','CustServ Calls'],drop_first=True)

X.head()

"""**separating train and test sets:**"""

from sklearn.model_selection import train_test_split

x_train , x_test , y_train , y_test = train_test_split(X,y, test_size = 0.30 ,random_state = 1)

"""**Scalling:**"""

from sklearn.preprocessing import MinMaxScaler
norm = MinMaxScaler().fit(x_train)
x_train = norm.transform(x_train)
x_test = norm.transform(x_test)

"""**model building:**

**Logistic regression:**
"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()

lr.fit(x_train,y_train)

logpred = lr.predict(x_test)

#Evaluation:
from sklearn.metrics import classification_report,accuracy_score
print(classification_report(y_test,logpred))

logacc = accuracy_score(y_test,logpred)
logacc

"""**Decision Tree:**"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()

dt.fit(x_train,y_train)

dtpred = dt.predict(x_test)

print(classification_report(y_test,dtpred))

dtacc = accuracy_score(y_test,dtpred)
dtacc

"""**Random forest:**"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=500)

rf.fit(x_train,y_train)

rfpred = rf.predict(x_test)

print(classification_report(y_test,rfpred))

rfacc = accuracy_score(y_test,rfpred)
rfacc

"""**XG boost:**"""

from xgboost import XGBClassifier

xgb = XGBClassifier()

xgb.fit(x_train,y_train)

xgbpred = xgb.predict(x_test)

print(classification_report(y_test,xgbpred))

xgbacc = accuracy_score(y_test,xgbpred)

xgbacc

"""**printing all accuracies:**"""

print('logistic regression: ',logacc)
print('decision tree: ',dtacc)
print('random forest: ',rfacc)
print('XG_Boost: ',xgbacc)

"""Among all the classifiers we applied, we got high accuracy with  XGBclassifier 

But we can't say it's best . because we used a single test set , which may be favourable to XGBoosting model. to check this we  compute other accuracies on other test sets . to do that we use k-fold cross validation.

**k-fold cross validation on XGBooosting model:**
"""

from sklearn.model_selection import cross_val_score

kxgaccs = cross_val_score(estimator=xgb,X=x_train,y=y_train,cv=10)

print("accuracy: {:.2f} %".format(kxgaccs.mean()*100))

"""we got final accuraacy of 94.25% on this model"""